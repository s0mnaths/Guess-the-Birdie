{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 315 Bird Species - Classification\n\nDataset found on kaggle: [https://www.kaggle.com/gpiosenka/100-bird-species](https://www.kaggle.com/gpiosenka/100-bird-species)","metadata":{"id":"FRShcD3UAJlV"}},{"cell_type":"markdown","source":"## Getting the data\n\nWe can use the [opendatasets](https://github.com/jovianml/opendatasets) library to download the the dataset from kaggle.","metadata":{"id":"B4E5--iDA6uE"}},{"cell_type":"code","source":"!pip install opendatasets --upgrade --quiet","metadata":{"id":"jLrWKpK8_w3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import opendatasets as od\n\nod.download('https://www.kaggle.com/gpiosenka/100-bird-species')","metadata":{"id":"GjxSMrtJAiHO","outputId":"4f0c2bfa-04d5-4833-c22c-57081a44ffb1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"d_4p82wtDjml"}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torchvision.utils import make_grid\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"5gB1bnYcAx49","execution":{"iopub.status.busy":"2021-12-03T11:32:06.180136Z","iopub.execute_input":"2021-12-03T11:32:06.180738Z","iopub.status.idle":"2021-12-03T11:32:08.016947Z","shell.execute_reply.started":"2021-12-03T11:32:06.180639Z","shell.execute_reply":"2021-12-03T11:32:08.015759Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the directory structure","metadata":{"id":"Hjmhoa2JTdQ8"}},{"cell_type":"code","source":"data_dir = '../input/100-bird-species'  \n\nprint(f'Directories: {os.listdir(data_dir)}')\nclasses = os.listdir(data_dir + \"/train\")\nprint(f'Number of classes: {len(classes)}')","metadata":{"id":"63rKfephE2JT","outputId":"660c8df6-0ca6-40ec-e5c5-ee8fd8d4de08","execution":{"iopub.status.busy":"2021-12-03T11:33:30.526847Z","iopub.execute_input":"2021-12-03T11:33:30.527108Z","iopub.status.idle":"2021-12-03T11:33:30.571883Z","shell.execute_reply.started":"2021-12-03T11:33:30.527079Z","shell.execute_reply":"2021-12-03T11:33:30.571198Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Defining Transforms","metadata":{"id":"EwBcn3QdU-lz"}},{"cell_type":"code","source":"stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n\ntrain_tfms = tt.Compose([tt.ToTensor(),\n                         tt.Normalize(*stats,inplace=True)])   \nvalid_tfms = tt.Compose([tt.ToTensor(),\n                         tt.Normalize(*stats)])   ","metadata":{"id":"ImY7loBOVCrS","outputId":"d57b2307-7734-4f79-d275-6d9cf94c35ce","execution":{"iopub.status.busy":"2021-12-03T11:33:33.361061Z","iopub.execute_input":"2021-12-03T11:33:33.361596Z","iopub.status.idle":"2021-12-03T11:33:33.368016Z","shell.execute_reply.started":"2021-12-03T11:33:33.361559Z","shell.execute_reply":"2021-12-03T11:33:33.366311Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Converting to PyTorch dataset format","metadata":{"id":"U67fn7_5T_lz"}},{"cell_type":"code","source":"train_ds = ImageFolder(data_dir+'/train', train_tfms) \nvalid_ds = ImageFolder(data_dir+'/valid', valid_tfms) \ntest_ds = ImageFolder(data_dir+'/test', valid_tfms) ","metadata":{"id":"JK8m2CaHSd-G","execution":{"iopub.status.busy":"2021-12-03T11:33:34.608322Z","iopub.execute_input":"2021-12-03T11:33:34.609061Z","iopub.status.idle":"2021-12-03T11:33:39.414961Z","shell.execute_reply.started":"2021-12-03T11:33:34.609005Z","shell.execute_reply":"2021-12-03T11:33:39.413980Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def dataset_info(dataset):\n    print(f'Size fo dataset: {len(dataset)}')\n    img, label = dataset[0]\n    print(f'Sample-01 Image size: {img.shape}, Label: {label}')\n    print(f'Number of classes: {len(dataset.classes)}\\n\\n')\n\nprint('Train Dataset\\n-----------')\ndataset_info(train_ds)\nprint('Validation Dataset\\n-----------')\ndataset_info(valid_ds)\nprint('Test Dataset\\n-----------')\ndataset_info(test_ds)","metadata":{"id":"7c6g7U81Wyft","outputId":"0a505653-170e-4d78-ccd6-adb5c474e537","execution":{"iopub.status.busy":"2021-12-03T11:33:40.571725Z","iopub.execute_input":"2021-12-03T11:33:40.572169Z","iopub.status.idle":"2021-12-03T11:33:40.646696Z","shell.execute_reply.started":"2021-12-03T11:33:40.572133Z","shell.execute_reply":"2021-12-03T11:33:40.646026Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Each image is a torch tensor of size `3x224x224`","metadata":{"id":"ByHRYTSTZrOs"}},{"cell_type":"markdown","source":"## Creating Dataloaders\nCreating dataloader to load data in batches for training.","metadata":{"id":"R3c7ozreaGFM"}},{"cell_type":"code","source":"batch_size = 256\n\ntrain_dl = DataLoader(train_ds, \n                      batch_size, \n                      shuffle=True, \n                      num_workers=2,  \n                      pin_memory=True)  \n\nvalid_dl = DataLoader(valid_ds, \n                    batch_size*2,    # for validation we'll not compute gradients, so we'll need half the memory. Therefore we can double the batch size.\n                    num_workers=2, \n                    pin_memory=True)\n","metadata":{"id":"BgcxVvx6W-Wa","execution":{"iopub.status.busy":"2021-12-03T11:33:45.415957Z","iopub.execute_input":"2021-12-03T11:33:45.416511Z","iopub.status.idle":"2021-12-03T11:33:45.424086Z","shell.execute_reply.started":"2021-12-03T11:33:45.416466Z","shell.execute_reply":"2021-12-03T11:33:45.423200Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Viewing a batch of dataset\nWe can look at batches of images from the dataset using the `make_grid` method from `torchvision`.\n\nSince we have normalized the color channels, to view the images we'll first have to denormlize them.","metadata":{"id":"-_aRviMPbzMS"}},{"cell_type":"code","source":"def denormalize(images, means, stds):\n    means = torch.tensor(means).reshape(1, 3, 1, 1)\n    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n    return images * stds + means\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        denorm_images = denormalize(images, *stats)\n        ax.imshow(make_grid(denorm_images[:100], nrow=10).permute(1, 2, 0).clamp(0,1))\n        break","metadata":{"id":"7q7OA6fdbvs3","execution":{"iopub.status.busy":"2021-12-03T11:33:46.465705Z","iopub.execute_input":"2021-12-03T11:33:46.466389Z","iopub.status.idle":"2021-12-03T11:33:46.473594Z","shell.execute_reply.started":"2021-12-03T11:33:46.466354Z","shell.execute_reply":"2021-12-03T11:33:46.472182Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"show_batch(train_dl)","metadata":{"id":"1Gf4FD10cS8C","outputId":"3f31c7e2-de80-4330-c591-49402e8c50f0","execution":{"iopub.status.busy":"2021-12-03T11:33:46.973912Z","iopub.execute_input":"2021-12-03T11:33:46.974464Z","iopub.status.idle":"2021-12-03T11:33:55.634637Z","shell.execute_reply.started":"2021-12-03T11:33:46.974419Z","shell.execute_reply":"2021-12-03T11:33:55.632655Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Defining the CNN model\n\nWe can define a Base class which will provide us with some helper functions for training and validation. We'll extend this base class to create the Model class.","metadata":{"id":"7NAy-CqndB8E"}},{"cell_type":"code","source":"class ClassificationBase(nn.Module):\n    def training_step(self, batch):  \n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            (epoch+1), result['train_loss'], result['val_loss'], result['val_acc']))\n        \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"id":"sRDll_0icVAc","execution":{"iopub.status.busy":"2021-12-03T11:33:55.636096Z","iopub.execute_input":"2021-12-03T11:33:55.636320Z","iopub.status.idle":"2021-12-03T11:33:55.649304Z","shell.execute_reply.started":"2021-12-03T11:33:55.636290Z","shell.execute_reply":"2021-12-03T11:33:55.648681Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Now extending this `ClassificationBase` to create the CNN","metadata":{"id":"gjSmCT08eR_x"}},{"cell_type":"code","source":"class WhatBirdie(ClassificationBase):\n    def __init__(self):\n        super().__init__()\n\n        #input: 3 x 224 x 224\n        self.conv1 = nn.Conv2d(3, 6, kernel_size=3, padding=1)\n        self.pool4 = nn.MaxPool2d(4, 4)\n        self.res1 = nn.Sequential(\n            nn.Conv2d(6, 6, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(6, 6, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        \n        self.conv2 = nn.Conv2d(6, 32, kernel_size=3, padding=1)\n        self.res2 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)\n\n        self.FConnected = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64*7*7, 700),\n            nn.ReLU(),\n            nn.Linear(700, 700),\n            nn.ReLU(),\n            nn.Linear(700, 315)\n        )\n        \n        \n    def forward(self, xb):\n        #input: 3 x 224 x 224\n        out = F.relu(self.conv1(xb))   # output: 6 x 224 x224\n        out = self.pool4(out)   # output: 6 x 56 x 56\n       \n        out = self.res1(out) + out   # output: 6 x 56 x 56\n       \n        out = F.relu(self.conv2(out))   # output: 32 x 56 x 56\n        out = self.pool4(out)    # output: 32 x 14 x 14\n       \n        out = self.res2(out) + out   # output: 32 x 14 x 14\n       \n        out = F.relu(self.conv3(out))    # output: 64 x 14 x 14\n        out = self.pool2(out)    # output: 64 x 7 x 7\n\n        out = self.FConnected(out)   \n\n        return out\n\n\n","metadata":{"id":"gcLZGwKfdKFd","execution":{"iopub.status.busy":"2021-12-03T11:49:09.019145Z","iopub.execute_input":"2021-12-03T11:49:09.019913Z","iopub.status.idle":"2021-12-03T11:49:09.033066Z","shell.execute_reply.started":"2021-12-03T11:49:09.019870Z","shell.execute_reply":"2021-12-03T11:49:09.031921Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"## Moving our dataloader & model to device\n","metadata":{"id":"OohO2QbasKzQ"}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)    # non-blocking indicates that the tensor will be moved to the GPU in a background thread\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"id":"GYTUGoJgpSV8","execution":{"iopub.status.busy":"2021-12-03T11:49:09.830063Z","iopub.execute_input":"2021-12-03T11:49:09.830701Z","iopub.status.idle":"2021-12-03T11:49:09.840269Z","shell.execute_reply.started":"2021-12-03T11:49:09.830665Z","shell.execute_reply":"2021-12-03T11:49:09.839529Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"id":"31c9hFxtsOdl","outputId":"f53198f1-fdf5-4d06-b0dd-d9b7bac323f0","execution":{"iopub.status.busy":"2021-12-03T11:49:10.224746Z","iopub.execute_input":"2021-12-03T11:49:10.225237Z","iopub.status.idle":"2021-12-03T11:49:10.233308Z","shell.execute_reply.started":"2021-12-03T11:49:10.225201Z","shell.execute_reply":"2021-12-03T11:49:10.230141Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"fXioUKqnx-80","execution":{"iopub.status.busy":"2021-12-03T11:49:10.670731Z","iopub.execute_input":"2021-12-03T11:49:10.670941Z","iopub.status.idle":"2021-12-03T11:49:10.683209Z","shell.execute_reply.started":"2021-12-03T11:49:10.670916Z","shell.execute_reply":"2021-12-03T11:49:10.682276Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"#### Using the above methods to move dataloader & model to device","metadata":{"id":"HcK7jeHJsSlc"}},{"cell_type":"code","source":"# Moves the dataloader to GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)\n\n# Instanciates & moves the model to GPU\nmodel = to_device(WhatBirdie(), device)","metadata":{"id":"aMhFom1WsQeg","execution":{"iopub.status.busy":"2021-12-03T11:49:11.664295Z","iopub.execute_input":"2021-12-03T11:49:11.664575Z","iopub.status.idle":"2021-12-03T11:49:11.699966Z","shell.execute_reply.started":"2021-12-03T11:49:11.664522Z","shell.execute_reply":"2021-12-03T11:49:11.699279Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"## Training & Validation functions","metadata":{"id":"muBrvJxcsrJe"}},{"cell_type":"code","source":"@torch.no_grad()   \ndef evaluate(model, val_loader):\n    model.eval()    \n    outputs = [model.validation_step(batch) for batch in val_loader]    # validation loss & acc for each batch\n    return model.validation_epoch_end(outputs)   # mean of validation loss & acc for each batch\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()    \n        train_losses = []           # losses for each batch in an epoch\n        for batch in train_loader:               # for each batch in the dataloader\n            loss = model.training_step(batch)      # calc loss for each batch using the fn we defined earlier\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()        # perform gradient descent\n            optimizer.zero_grad()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)    # validation loss & acc for that epoch\n        result['train_loss'] = torch.stack(train_losses).mean().item()   # mean of training loss that we calculated batchwise\n        model.epoch_end(epoch, result)   \n        history.append(result)\n    return history     # fit fn returns the training history of the model","metadata":{"id":"RGcNXBTWsoI2","execution":{"iopub.status.busy":"2021-12-03T11:49:15.249242Z","iopub.execute_input":"2021-12-03T11:49:15.249494Z","iopub.status.idle":"2021-12-03T11:49:15.258651Z","shell.execute_reply.started":"2021-12-03T11:49:15.249466Z","shell.execute_reply":"2021-12-03T11:49:15.257720Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Before training, let's see how it performs on validation set with inital parameters","metadata":{"id":"P0pMAvm1tA_D"}},{"cell_type":"code","source":"evaluate(model, valid_dl)","metadata":{"id":"Rs7Vd8jatRzI","outputId":"5f74c58f-9094-4389-a192-8400f0e282c2","execution":{"iopub.status.busy":"2021-12-03T11:49:16.408946Z","iopub.execute_input":"2021-12-03T11:49:16.409224Z","iopub.status.idle":"2021-12-03T11:49:21.377310Z","shell.execute_reply.started":"2021-12-03T11:49:16.409196Z","shell.execute_reply":"2021-12-03T11:49:21.376450Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"## Set Training Hyperparameters","metadata":{"id":"VtVU-Ju4tqm9"}},{"cell_type":"code","source":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 0.001","metadata":{"id":"-dwZ9OMqtW3I","execution":{"iopub.status.busy":"2021-12-03T11:49:24.863427Z","iopub.execute_input":"2021-12-03T11:49:24.864255Z","iopub.status.idle":"2021-12-03T11:49:24.868383Z","shell.execute_reply.started":"2021-12-03T11:49:24.864205Z","shell.execute_reply":"2021-12-03T11:49:24.867584Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model","metadata":{"id":"rKGxcBHVt0Vb"}},{"cell_type":"code","source":"%%time\nhistory = fit(num_epochs, lr, model, train_dl, valid_dl, opt_func)","metadata":{"id":"HK-QIXSGtzh_","outputId":"94c5cb55-87b9-4f40-9721-ed643fc39295","execution":{"iopub.status.busy":"2021-12-03T11:49:26.259894Z","iopub.execute_input":"2021-12-03T11:49:26.260416Z","iopub.status.idle":"2021-12-03T12:07:41.924903Z","shell.execute_reply.started":"2021-12-03T11:49:26.260377Z","shell.execute_reply":"2021-12-03T12:07:41.923841Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"## Plot accuracy\nPlot validation set accuracy","metadata":{"id":"oIy1PJal9e9u"}},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","metadata":{"id":"f16pvulZt6XG","execution":{"iopub.status.busy":"2021-12-03T12:08:12.470641Z","iopub.execute_input":"2021-12-03T12:08:12.471300Z","iopub.status.idle":"2021-12-03T12:08:12.477195Z","shell.execute_reply.started":"2021-12-03T12:08:12.471259Z","shell.execute_reply":"2021-12-03T12:08:12.476370Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"id":"ZwfOuYuK93DK","outputId":"faddc161-244a-418a-bb97-01234677a7f3","execution":{"iopub.status.busy":"2021-12-03T12:08:13.249134Z","iopub.execute_input":"2021-12-03T12:08:13.249768Z","iopub.status.idle":"2021-12-03T12:08:23.481068Z","shell.execute_reply.started":"2021-12-03T12:08:13.249724Z","shell.execute_reply":"2021-12-03T12:08:23.480358Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"## Plot Losses\n\nPlot losses of training & validation set","metadata":{"id":"XnTfbA8z-IXA"}},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","metadata":{"id":"E4cUxhez94_J","execution":{"iopub.status.busy":"2021-12-03T12:08:23.482603Z","iopub.execute_input":"2021-12-03T12:08:23.483669Z","iopub.status.idle":"2021-12-03T12:08:23.489837Z","shell.execute_reply.started":"2021-12-03T12:08:23.483628Z","shell.execute_reply":"2021-12-03T12:08:23.489141Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"id":"F4PTYRSs-QM8","outputId":"853f7d0a-83c2-4319-ec25-988a96365700","execution":{"iopub.status.busy":"2021-12-03T12:08:23.490978Z","iopub.execute_input":"2021-12-03T12:08:23.491874Z","iopub.status.idle":"2021-12-03T12:08:23.710202Z","shell.execute_reply.started":"2021-12-03T12:08:23.491831Z","shell.execute_reply":"2021-12-03T12:08:23.709508Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"We see that after epoch 6th, the `val_loss` started increasing a bit. This shows sign of overfitting. We should add some regularization techniques.","metadata":{"id":"FMsohilB-XEX"}},{"cell_type":"markdown","source":"## Testing the model on the whole Test set","metadata":{"id":"GyC2NU3E-w6g"}},{"cell_type":"code","source":"test_dl = DeviceDataLoader(DataLoader(test_ds, batch_size*2), device)\nresult = evaluate(model, test_dl)\nval_loss, val_acc = result.values()\nprint(f'Accuracy: {val_acc*100:.4f} %, Loss: {val_loss:.4f}')","metadata":{"id":"iQHMzeqt-U-D","outputId":"ee462313-1c10-42a4-a071-9e61b39e0c46","execution":{"iopub.status.busy":"2021-12-03T12:08:23.711960Z","iopub.execute_input":"2021-12-03T12:08:23.712427Z","iopub.status.idle":"2021-12-03T12:08:35.539752Z","shell.execute_reply.started":"2021-12-03T12:08:23.712388Z","shell.execute_reply":"2021-12-03T12:08:35.538901Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{"id":"P86ZnbCjADOL"}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'WhatBirdies.pth')","metadata":{"id":"piUFfJI3_EKr","execution":{"iopub.status.busy":"2021-12-03T12:08:38.003740Z","iopub.execute_input":"2021-12-03T12:08:38.004063Z","iopub.status.idle":"2021-12-03T12:08:38.031220Z","shell.execute_reply.started":"2021-12-03T12:08:38.004033Z","shell.execute_reply":"2021-12-03T12:08:38.030490Z"},"trusted":true},"execution_count":48,"outputs":[]}]}