{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 315 Bird Species - Classification\n\nDataset found on kaggle: [https://www.kaggle.com/gpiosenka/100-bird-species](https://www.kaggle.com/gpiosenka/100-bird-species)","metadata":{"id":"FRShcD3UAJlV"}},{"cell_type":"markdown","source":"## Getting the data\n\nWe can use the [opendatasets](https://github.com/jovianml/opendatasets) library to download the the dataset from kaggle.","metadata":{"id":"B4E5--iDA6uE"}},{"cell_type":"code","source":"# !pip install opendatasets --upgrade --quiet","metadata":{"id":"jLrWKpK8_w3q","execution":{"iopub.status.busy":"2021-12-03T13:05:35.861345Z","iopub.execute_input":"2021-12-03T13:05:35.862140Z","iopub.status.idle":"2021-12-03T13:05:35.885466Z","shell.execute_reply.started":"2021-12-03T13:05:35.862011Z","shell.execute_reply":"2021-12-03T13:05:35.884814Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# import opendatasets as od\n\n# od.download('https://www.kaggle.com/gpiosenka/100-bird-species')","metadata":{"id":"GjxSMrtJAiHO","outputId":"4f0c2bfa-04d5-4833-c22c-57081a44ffb1","execution":{"iopub.status.busy":"2021-12-03T13:05:35.886926Z","iopub.execute_input":"2021-12-03T13:05:35.887241Z","iopub.status.idle":"2021-12-03T13:05:35.891300Z","shell.execute_reply.started":"2021-12-03T13:05:35.887206Z","shell.execute_reply":"2021-12-03T13:05:35.890495Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{"id":"d_4p82wtDjml"}},{"cell_type":"code","source":"import os\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport numpy as np\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as tt\nfrom torchvision.utils import make_grid\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"id":"5gB1bnYcAx49","execution":{"iopub.status.busy":"2021-12-03T13:05:35.892795Z","iopub.execute_input":"2021-12-03T13:05:35.893040Z","iopub.status.idle":"2021-12-03T13:05:37.716866Z","shell.execute_reply.started":"2021-12-03T13:05:35.893007Z","shell.execute_reply":"2021-12-03T13:05:37.715998Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Understanding the directory structure","metadata":{"id":"Hjmhoa2JTdQ8"}},{"cell_type":"code","source":"data_dir = '../input/100-bird-species'  \n\nprint(f'Directories: {os.listdir(data_dir)}')\nclasses = os.listdir(data_dir + \"/train\")\nprint(f'Number of classes: {len(classes)}')","metadata":{"id":"63rKfephE2JT","outputId":"660c8df6-0ca6-40ec-e5c5-ee8fd8d4de08","execution":{"iopub.status.busy":"2021-12-03T13:05:37.718991Z","iopub.execute_input":"2021-12-03T13:05:37.719256Z","iopub.status.idle":"2021-12-03T13:05:37.761938Z","shell.execute_reply.started":"2021-12-03T13:05:37.719221Z","shell.execute_reply":"2021-12-03T13:05:37.761151Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Defining Transforms","metadata":{"id":"EwBcn3QdU-lz"}},{"cell_type":"code","source":"stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n\ntrain_tfms = tt.Compose([tt.RandomCrop(224, padding=14, padding_mode='reflect'),\n                         tt.RandomHorizontalFlip(),\n                         tt.ToTensor(),\n                         tt.Normalize(*stats,inplace=True)])   \nvalid_tfms = tt.Compose([tt.ToTensor(),\n                         tt.Normalize(*stats)])   ","metadata":{"id":"ImY7loBOVCrS","outputId":"d57b2307-7734-4f79-d275-6d9cf94c35ce","execution":{"iopub.status.busy":"2021-12-03T13:05:37.763009Z","iopub.execute_input":"2021-12-03T13:05:37.763748Z","iopub.status.idle":"2021-12-03T13:05:37.769531Z","shell.execute_reply.started":"2021-12-03T13:05:37.763708Z","shell.execute_reply":"2021-12-03T13:05:37.768621Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Converting to PyTorch dataset format","metadata":{"id":"U67fn7_5T_lz"}},{"cell_type":"code","source":"train_ds = ImageFolder(data_dir+'/train', train_tfms) \nvalid_ds = ImageFolder(data_dir+'/valid', valid_tfms) \ntest_ds = ImageFolder(data_dir+'/test', valid_tfms) ","metadata":{"id":"JK8m2CaHSd-G","execution":{"iopub.status.busy":"2021-12-03T13:05:37.770872Z","iopub.execute_input":"2021-12-03T13:05:37.771734Z","iopub.status.idle":"2021-12-03T13:05:43.226978Z","shell.execute_reply.started":"2021-12-03T13:05:37.771634Z","shell.execute_reply":"2021-12-03T13:05:43.226216Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def dataset_info(dataset):\n    print(f'Size fo dataset: {len(dataset)}')\n    img, label = dataset[0]\n    print(f'Sample-01 Image size: {img.shape}, Label: {label}')\n    print(f'Number of classes: {len(dataset.classes)}\\n\\n')\n\nprint('Train Dataset\\n-----------')\ndataset_info(train_ds)\nprint('Validation Dataset\\n-----------')\ndataset_info(valid_ds)\nprint('Test Dataset\\n-----------')\ndataset_info(test_ds)","metadata":{"id":"7c6g7U81Wyft","outputId":"0a505653-170e-4d78-ccd6-adb5c474e537","execution":{"iopub.status.busy":"2021-12-03T13:05:43.229449Z","iopub.execute_input":"2021-12-03T13:05:43.229923Z","iopub.status.idle":"2021-12-03T13:05:43.331149Z","shell.execute_reply.started":"2021-12-03T13:05:43.229880Z","shell.execute_reply":"2021-12-03T13:05:43.330417Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Each image is a torch tensor of size `3x224x224`","metadata":{"id":"ByHRYTSTZrOs"}},{"cell_type":"markdown","source":"## Creating Dataloaders\nCreating dataloader to load data in batches for training.","metadata":{"id":"R3c7ozreaGFM"}},{"cell_type":"code","source":"batch_size = 256\n\ntrain_dl = DataLoader(train_ds, \n                      batch_size, \n                      shuffle=True, \n                      num_workers=2,  \n                      pin_memory=True)  \n\nvalid_dl = DataLoader(valid_ds, \n                    batch_size*2,    # for validation we'll not compute gradients, so we'll need half the memory. Therefore we can double the batch size.\n                    num_workers=2, \n                    pin_memory=True)\n","metadata":{"id":"BgcxVvx6W-Wa","execution":{"iopub.status.busy":"2021-12-03T13:05:43.333767Z","iopub.execute_input":"2021-12-03T13:05:43.334316Z","iopub.status.idle":"2021-12-03T13:05:43.339277Z","shell.execute_reply.started":"2021-12-03T13:05:43.334274Z","shell.execute_reply":"2021-12-03T13:05:43.338544Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Viewing a batch of dataset\nWe can look at batches of images from the dataset using the `make_grid` method from `torchvision`.\n\nSince we have normalized the color channels, to view the images we'll first have to denormlize them.","metadata":{"id":"-_aRviMPbzMS"}},{"cell_type":"code","source":"def denormalize(images, means, stds):\n    means = torch.tensor(means).reshape(1, 3, 1, 1)\n    stds = torch.tensor(stds).reshape(1, 3, 1, 1)\n    return images * stds + means\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 12))\n        ax.set_xticks([]); ax.set_yticks([])\n        denorm_images = denormalize(images, *stats)\n        ax.imshow(make_grid(denorm_images[:100], nrow=10).permute(1, 2, 0).clamp(0,1))\n        break","metadata":{"id":"7q7OA6fdbvs3","execution":{"iopub.status.busy":"2021-12-03T13:05:43.340587Z","iopub.execute_input":"2021-12-03T13:05:43.341107Z","iopub.status.idle":"2021-12-03T13:05:43.352395Z","shell.execute_reply.started":"2021-12-03T13:05:43.341069Z","shell.execute_reply":"2021-12-03T13:05:43.351597Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"show_batch(train_dl)","metadata":{"id":"1Gf4FD10cS8C","outputId":"3f31c7e2-de80-4330-c591-49402e8c50f0","execution":{"iopub.status.busy":"2021-12-03T13:05:43.353904Z","iopub.execute_input":"2021-12-03T13:05:43.354376Z","iopub.status.idle":"2021-12-03T13:05:52.993954Z","shell.execute_reply.started":"2021-12-03T13:05:43.354338Z","shell.execute_reply":"2021-12-03T13:05:52.993134Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Defining the CNN model\n\nWe can define a Base class which will provide us with some helper functions for training and validation. We'll extend this base class to create the Model class.","metadata":{"id":"7NAy-CqndB8E"}},{"cell_type":"code","source":"class ClassificationBase(nn.Module):\n    def training_step(self, batch):  \n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            (epoch+1), result['train_loss'], result['val_loss'], result['val_acc']))\n        \ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))","metadata":{"id":"sRDll_0icVAc","execution":{"iopub.status.busy":"2021-12-03T13:05:52.995414Z","iopub.execute_input":"2021-12-03T13:05:52.995722Z","iopub.status.idle":"2021-12-03T13:05:53.009291Z","shell.execute_reply.started":"2021-12-03T13:05:52.995678Z","shell.execute_reply":"2021-12-03T13:05:53.008439Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Now extending this `ClassificationBase` to create the CNN","metadata":{"id":"gjSmCT08eR_x"}},{"cell_type":"code","source":"class WhatBirdie(ClassificationBase):\n    def __init__(self):\n        super().__init__()\n\n        #input: 3 x 224 x 224\n        self.conv1 = nn.Conv2d(3, 6, kernel_size=3, padding=1)\n        self.pool4 = nn.MaxPool2d(4, 4)\n        self.res1 = nn.Sequential(\n            nn.Conv2d(6, 6, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(6, 6, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n        \n        self.conv2 = nn.Conv2d(6, 32, kernel_size=3, padding=1)\n        self.res2 = nn.Sequential(\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n            nn.ReLU()\n        )\n\n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.pool2 = nn.MaxPool2d(2, 2)\n\n        self.FConnected = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64*7*7, 700),\n            nn.ReLU(),\n            nn.Linear(700, 700),\n            nn.ReLU(),\n            nn.Linear(700, 315)\n        )\n        \n        \n    def forward(self, xb):\n        #input: 3 x 224 x 224\n        out = F.relu(self.conv1(xb))   # output: 6 x 224 x224\n        out = self.pool4(out)   # output: 6 x 56 x 56\n       \n        out = self.res1(out) + out   # output: 6 x 56 x 56\n       \n        out = F.relu(self.conv2(out))   # output: 32 x 56 x 56\n        out = self.pool4(out)    # output: 32 x 14 x 14\n       \n        out = self.res2(out) + out   # output: 32 x 14 x 14\n       \n        out = F.relu(self.conv3(out))    # output: 64 x 14 x 14\n        out = self.pool2(out)    # output: 64 x 7 x 7\n\n        out = self.FConnected(out)   \n\n        return out\n\n\n","metadata":{"id":"gcLZGwKfdKFd","execution":{"iopub.status.busy":"2021-12-03T13:05:53.010972Z","iopub.execute_input":"2021-12-03T13:05:53.011603Z","iopub.status.idle":"2021-12-03T13:05:53.028700Z","shell.execute_reply.started":"2021-12-03T13:05:53.011568Z","shell.execute_reply":"2021-12-03T13:05:53.027837Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Moving our dataloader & model to device\n","metadata":{"id":"OohO2QbasKzQ"}},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)    # non-blocking indicates that the tensor will be moved to the GPU in a background thread\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"id":"GYTUGoJgpSV8","execution":{"iopub.status.busy":"2021-12-03T13:05:53.030341Z","iopub.execute_input":"2021-12-03T13:05:53.030930Z","iopub.status.idle":"2021-12-03T13:05:53.044266Z","shell.execute_reply.started":"2021-12-03T13:05:53.030896Z","shell.execute_reply":"2021-12-03T13:05:53.043426Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"id":"31c9hFxtsOdl","outputId":"f53198f1-fdf5-4d06-b0dd-d9b7bac323f0","execution":{"iopub.status.busy":"2021-12-03T13:05:53.046168Z","iopub.execute_input":"2021-12-03T13:05:53.046773Z","iopub.status.idle":"2021-12-03T13:05:53.059058Z","shell.execute_reply.started":"2021-12-03T13:05:53.046717Z","shell.execute_reply":"2021-12-03T13:05:53.058301Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"fXioUKqnx-80","execution":{"iopub.status.busy":"2021-12-03T13:05:53.060433Z","iopub.execute_input":"2021-12-03T13:05:53.060756Z","iopub.status.idle":"2021-12-03T13:05:53.068337Z","shell.execute_reply.started":"2021-12-03T13:05:53.060712Z","shell.execute_reply":"2021-12-03T13:05:53.067474Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"#### Using the above methods to move dataloader & model to device","metadata":{"id":"HcK7jeHJsSlc"}},{"cell_type":"code","source":"# Moves the dataloader to GPU\ntrain_dl = DeviceDataLoader(train_dl, device)\nvalid_dl = DeviceDataLoader(valid_dl, device)\n\n# Instanciates & moves the model to GPU\nmodel = to_device(WhatBirdie(), device)","metadata":{"id":"aMhFom1WsQeg","execution":{"iopub.status.busy":"2021-12-03T13:05:53.069191Z","iopub.execute_input":"2021-12-03T13:05:53.069387Z","iopub.status.idle":"2021-12-03T13:05:53.113005Z","shell.execute_reply.started":"2021-12-03T13:05:53.069365Z","shell.execute_reply":"2021-12-03T13:05:53.112346Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## Training & Validation functions","metadata":{"id":"muBrvJxcsrJe"}},{"cell_type":"code","source":"@torch.no_grad()   \ndef evaluate(model, val_loader):\n    model.eval()    \n    outputs = [model.validation_step(batch) for batch in val_loader]    # validation loss & acc for each batch\n    return model.validation_epoch_end(outputs)   # mean of validation loss & acc for each batch\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training Phase \n        model.train()    \n        train_losses = []           # losses for each batch in an epoch\n        for batch in train_loader:               # for each batch in the dataloader\n            loss = model.training_step(batch)      # calc loss for each batch using the fn we defined earlier\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()        # perform gradient descent\n            optimizer.zero_grad()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)    # validation loss & acc for that epoch\n        result['train_loss'] = torch.stack(train_losses).mean().item()   # mean of training loss that we calculated batchwise\n        model.epoch_end(epoch, result)   \n        history.append(result)\n    return history     # fit fn returns the training history of the model","metadata":{"id":"RGcNXBTWsoI2","execution":{"iopub.status.busy":"2021-12-03T13:05:53.115691Z","iopub.execute_input":"2021-12-03T13:05:53.116150Z","iopub.status.idle":"2021-12-03T13:05:53.125207Z","shell.execute_reply.started":"2021-12-03T13:05:53.116115Z","shell.execute_reply":"2021-12-03T13:05:53.124144Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Before training, let's see how it performs on validation set with inital parameters","metadata":{"id":"P0pMAvm1tA_D"}},{"cell_type":"code","source":"evaluate(model, valid_dl)","metadata":{"id":"Rs7Vd8jatRzI","outputId":"5f74c58f-9094-4389-a192-8400f0e282c2","execution":{"iopub.status.busy":"2021-12-03T13:05:53.126724Z","iopub.execute_input":"2021-12-03T13:05:53.126977Z","iopub.status.idle":"2021-12-03T13:06:03.609296Z","shell.execute_reply.started":"2021-12-03T13:05:53.126945Z","shell.execute_reply":"2021-12-03T13:06:03.608497Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Set Training Hyperparameters","metadata":{"id":"VtVU-Ju4tqm9"}},{"cell_type":"code","source":"num_epochs = 10\nopt_func = torch.optim.Adam\nlr = 0.001","metadata":{"id":"-dwZ9OMqtW3I","execution":{"iopub.status.busy":"2021-12-03T13:06:03.610863Z","iopub.execute_input":"2021-12-03T13:06:03.611446Z","iopub.status.idle":"2021-12-03T13:06:03.616214Z","shell.execute_reply.started":"2021-12-03T13:06:03.611406Z","shell.execute_reply":"2021-12-03T13:06:03.615527Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model","metadata":{"id":"rKGxcBHVt0Vb"}},{"cell_type":"code","source":"%%time\nhistory = fit(num_epochs, lr, model, train_dl, valid_dl, opt_func)","metadata":{"id":"HK-QIXSGtzh_","outputId":"94c5cb55-87b9-4f40-9721-ed643fc39295","execution":{"iopub.status.busy":"2021-12-03T13:06:03.619711Z","iopub.execute_input":"2021-12-03T13:06:03.620274Z","iopub.status.idle":"2021-12-03T13:25:43.634582Z","shell.execute_reply.started":"2021-12-03T13:06:03.620236Z","shell.execute_reply":"2021-12-03T13:25:43.633702Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Plot accuracy\nPlot validation set accuracy","metadata":{"id":"oIy1PJal9e9u"}},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","metadata":{"id":"f16pvulZt6XG","execution":{"iopub.status.busy":"2021-12-03T13:25:54.766109Z","iopub.execute_input":"2021-12-03T13:25:54.766521Z","iopub.status.idle":"2021-12-03T13:25:54.771464Z","shell.execute_reply.started":"2021-12-03T13:25:54.766484Z","shell.execute_reply":"2021-12-03T13:25:54.770697Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"id":"ZwfOuYuK93DK","outputId":"faddc161-244a-418a-bb97-01234677a7f3","execution":{"iopub.status.busy":"2021-12-03T13:25:54.772835Z","iopub.execute_input":"2021-12-03T13:25:54.773114Z","iopub.status.idle":"2021-12-03T13:25:54.965134Z","shell.execute_reply.started":"2021-12-03T13:25:54.773079Z","shell.execute_reply":"2021-12-03T13:25:54.964443Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"## Plot Losses\n\nPlot losses of training & validation set","metadata":{"id":"XnTfbA8z-IXA"}},{"cell_type":"code","source":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","metadata":{"id":"E4cUxhez94_J","execution":{"iopub.status.busy":"2021-12-03T13:25:54.966528Z","iopub.execute_input":"2021-12-03T13:25:54.966959Z","iopub.status.idle":"2021-12-03T13:25:54.973387Z","shell.execute_reply.started":"2021-12-03T13:25:54.966919Z","shell.execute_reply":"2021-12-03T13:25:54.972597Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"id":"F4PTYRSs-QM8","outputId":"853f7d0a-83c2-4319-ec25-988a96365700","execution":{"iopub.status.busy":"2021-12-03T13:25:54.974785Z","iopub.execute_input":"2021-12-03T13:25:54.975032Z","iopub.status.idle":"2021-12-03T13:25:55.180269Z","shell.execute_reply.started":"2021-12-03T13:25:54.974998Z","shell.execute_reply":"2021-12-03T13:25:55.179511Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"We see that after epoch 6th, the `val_loss` started increasing a bit. This shows sign of overfitting. We should add some regularization techniques.","metadata":{"id":"FMsohilB-XEX"}},{"cell_type":"markdown","source":"## Testing the model on the whole Test set","metadata":{"id":"GyC2NU3E-w6g"}},{"cell_type":"code","source":"test_dl = DeviceDataLoader(DataLoader(test_ds, batch_size*2), device)\nresult = evaluate(model, test_dl)\nval_loss, val_acc = result.values()\nprint(f'Accuracy: {val_acc*100:.4f} %, Loss: {val_loss:.4f}')","metadata":{"id":"iQHMzeqt-U-D","outputId":"ee462313-1c10-42a4-a071-9e61b39e0c46","execution":{"iopub.status.busy":"2021-12-03T13:25:55.181778Z","iopub.execute_input":"2021-12-03T13:25:55.182247Z","iopub.status.idle":"2021-12-03T13:25:59.174149Z","shell.execute_reply.started":"2021-12-03T13:25:55.182195Z","shell.execute_reply":"2021-12-03T13:25:59.172356Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{"id":"P86ZnbCjADOL"}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'WhatBirdies.pth')","metadata":{"id":"piUFfJI3_EKr","execution":{"iopub.status.busy":"2021-12-03T13:34:25.581937Z","iopub.execute_input":"2021-12-03T13:34:25.582655Z","iopub.status.idle":"2021-12-03T13:34:25.618169Z","shell.execute_reply.started":"2021-12-03T13:34:25.582607Z","shell.execute_reply":"2021-12-03T13:34:25.617342Z"},"trusted":true},"execution_count":32,"outputs":[]}]}